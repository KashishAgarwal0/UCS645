{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cTFqZ1MInlM"
      },
      "outputs": [],
      "source": [
        "#Q-1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sum_tasks_debug.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define N 1024\n",
        "\n",
        "__global__ void sumTasks(int* output) {\n",
        "    int tid = threadIdx.x;\n",
        "\n",
        "    if (tid == 0) {\n",
        "        printf(\"Thread 0 running (iterative sum)...\\n\");\n",
        "        int sum = 0;\n",
        "        for (int i = 1; i <= N; i++) {\n",
        "            sum += i;\n",
        "        }\n",
        "        output[0] = sum;\n",
        "    }\n",
        "    else if (tid == 1) {\n",
        "        printf(\"Thread 1 running (formula sum)...\\n\");\n",
        "        output[1] = N * (N + 1) / 2;\n",
        "    }\n",
        "}\n",
        "\n",
        "void checkCudaError(cudaError_t err, const char* msg) {\n",
        "    if (err != cudaSuccess) {\n",
        "        std::cerr << \"CUDA Error: \" << msg << \" -> \" << cudaGetErrorString(err) << std::endl;\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int h_output[2] = {0, 0};\n",
        "    int* d_output;\n",
        "\n",
        "    // Allocate memory\n",
        "    checkCudaError(cudaMalloc((void**)&d_output, 2 * sizeof(int)), \"Allocating device memory\");\n",
        "\n",
        "    // Initialize device memory to 0\n",
        "    checkCudaError(cudaMemset(d_output, 0, 2 * sizeof(int)), \"Memset device memory\");\n",
        "\n",
        "    // Launch kernel\n",
        "    sumTasks<<<1, 2>>>(d_output);\n",
        "\n",
        "    // Check kernel launch error\n",
        "    checkCudaError(cudaGetLastError(), \"Launching kernel\");\n",
        "\n",
        "    // Sync to ensure it's done\n",
        "    checkCudaError(cudaDeviceSynchronize(), \"Synchronizing device\");\n",
        "\n",
        "    // Copy result back\n",
        "    checkCudaError(cudaMemcpy(h_output, d_output, 2 * sizeof(int), cudaMemcpyDeviceToHost), \"Copying back results\");\n",
        "\n",
        "    std::cout << \"Iterative sum (Thread 0): \" << h_output[0] << std::endl;\n",
        "    std::cout << \"Formula sum (Thread 1): \" << h_output[1] << std::endl;\n",
        "\n",
        "    cudaFree(d_output);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWMlmimPOBZ0",
        "outputId": "064daa58-30a1-40ac-f262-e96a205f79fa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing sum_tasks_debug.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 sum_tasks_debug.cu -o sum_tasks_debug"
      ],
      "metadata": {
        "id": "XJjxBC83ODGr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./sum_tasks_debug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0QmBLXaOLZf",
        "outputId": "265d342a-12b3-4a58-8fbf-ce32958d6e8e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thread 1 running (formula sum)...\n",
            "Thread 0 running (iterative sum)...\n",
            "Iterative sum (Thread 0): 524800\n",
            "Formula sum (Thread 1): 524800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q-2(a)CPU pipelined merge sort"
      ],
      "metadata": {
        "id": "YiqVMcvtO_L1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile pipelined_merge_sort.cpp\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <omp.h>\n",
        "#include <chrono>\n",
        "#include <algorithm>\n",
        "\n",
        "#define N 1000\n",
        "\n",
        "void merge(std::vector<int>& arr, int left, int mid, int right) {\n",
        "    std::vector<int> leftPart(arr.begin() + left, arr.begin() + mid + 1);\n",
        "    std::vector<int> rightPart(arr.begin() + mid + 1, arr.begin() + right + 1);\n",
        "\n",
        "    int i = 0, j = 0, k = left;\n",
        "    while (i < leftPart.size() && j < rightPart.size()) {\n",
        "        if (leftPart[i] < rightPart[j]) arr[k++] = leftPart[i++];\n",
        "        else arr[k++] = rightPart[j++];\n",
        "    }\n",
        "\n",
        "    while (i < leftPart.size()) arr[k++] = leftPart[i++];\n",
        "    while (j < rightPart.size()) arr[k++] = rightPart[j++];\n",
        "}\n",
        "\n",
        "void parallelMergeSort(std::vector<int>& arr, int left, int right, int depth = 0) {\n",
        "    if (left >= right) return;\n",
        "    int mid = (left + right) / 2;\n",
        "\n",
        "    if (depth < 3) {\n",
        "        #pragma omp parallel sections\n",
        "        {\n",
        "            #pragma omp section\n",
        "            parallelMergeSort(arr, left, mid, depth + 1);\n",
        "\n",
        "            #pragma omp section\n",
        "            parallelMergeSort(arr, mid + 1, right, depth + 1);\n",
        "        }\n",
        "    } else {\n",
        "        parallelMergeSort(arr, left, mid, depth + 1);\n",
        "        parallelMergeSort(arr, mid + 1, right, depth + 1);\n",
        "    }\n",
        "\n",
        "    merge(arr, left, mid, right);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    std::vector<int> arr(N);\n",
        "    for (int i = 0; i < N; ++i)\n",
        "        arr[i] = rand() % 1000;\n",
        "\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "    parallelMergeSort(arr, 0, N - 1);\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    double time = std::chrono::duration<double, std::milli>(end - start).count();\n",
        "    std::cout << \"CPU Parallel (Pipelined) Merge Sort Time: \" << time << \" ms\" << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1gVqLldPBzT",
        "outputId": "f5e9db8b-4acc-4696-b9f6-fe9db5b84582"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing pipelined_merge_sort.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ -fopenmp pipelined_merge_sort.cpp -o pipelined_merge_sort"
      ],
      "metadata": {
        "id": "qZjhc6G-PKre"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./pipelined_merge_sort"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4Sx1dO8PQYy",
        "outputId": "0dd9e4e8-0d54-411a-ebeb-fcfb1d0ee5fe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Parallel (Pipelined) Merge Sort Time: 0.693341 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#(b)\n",
        "%%writefile cuda_merge_sort.cu\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "#include <stdlib.h>\n",
        "#include <chrono>\n",
        "\n",
        "#define N 1000\n",
        "\n",
        "__device__ void merge(int* input, int* temp, int left, int mid, int right) {\n",
        "    int i = left, j = mid + 1, k = left;\n",
        "    while (i <= mid && j <= right) {\n",
        "        if (input[i] <= input[j]) temp[k++] = input[i++];\n",
        "        else temp[k++] = input[j++];\n",
        "    }\n",
        "    while (i <= mid) temp[k++] = input[i++];\n",
        "    while (j <= right) temp[k++] = input[j++];\n",
        "    for (int l = left; l <= right; l++) input[l] = temp[l];\n",
        "}\n",
        "\n",
        "__global__ void mergeSortKernel(int* input, int* temp, int width, int size) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int left = tid * width * 2;\n",
        "    if (left + width < size) {\n",
        "        int mid = left + width - 1;\n",
        "        int right = min(left + 2 * width - 1, size - 1);\n",
        "        merge(input, temp, left, mid, right);\n",
        "    }\n",
        "}\n",
        "\n",
        "void mergeSortGPU(int* h_input) {\n",
        "    int* d_input;\n",
        "    int* d_temp;\n",
        "\n",
        "    cudaMalloc(&d_input, N * sizeof(int));\n",
        "    cudaMalloc(&d_temp, N * sizeof(int));\n",
        "    cudaMemcpy(d_input, h_input, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    for (int width = 1; width < N; width *= 2) {\n",
        "        int numBlocks = (N / (2 * width)) + 1;\n",
        "        mergeSortKernel<<<numBlocks, 1>>>(d_input, d_temp, width, N);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(h_input, d_input, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_temp);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int* arr = new int[N];\n",
        "    for (int i = 0; i < N; ++i)\n",
        "        arr[i] = rand() % 1000;\n",
        "\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "    mergeSortGPU(arr);\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    double time = std::chrono::duration<double, std::milli>(end - start).count();\n",
        "    std::cout << \"CUDA Merge Sort Time: \" << time << \" ms\" << std::endl;\n",
        "\n",
        "    delete[] arr;\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EF7lPncPS9_",
        "outputId": "0de2be51-909b-4249-ad07-3cdd8bde7223"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_merge_sort.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 cuda_merge_sort.cu -o cuda_merge_sort\n",
        "!./cuda_merge_sort"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BMQ_bhSPZyQ",
        "outputId": "7b21fb5a-b1bb-48ee-eb42-941ebae55b02"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Merge Sort Time: 200.04 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TULvuhdjSDzL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}