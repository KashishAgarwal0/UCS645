{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VhaXRl6LTxmZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e1c0ed6-8016-4d1f-9171-66865ec0bbd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vector_add_bandwidth.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile vector_add_bandwidth.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#include <chrono>\n",
        "\n",
        "#define N 1024\n",
        "\n",
        "// Statically defined device arrays\n",
        "__device__ int d_A[N];\n",
        "__device__ int d_B[N];\n",
        "__device__ int d_C[N];\n",
        "\n",
        "// Kernel: Add vectors\n",
        "__global__ void vectorAdd() {\n",
        "    int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (i < N) {\n",
        "        d_C[i] = d_A[i] + d_B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Host arrays\n",
        "int h_A[N], h_B[N], h_C[N];\n",
        "\n",
        "int main() {\n",
        "    // Fill host arrays\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        h_A[i] = i;\n",
        "        h_B[i] = 2 * i;\n",
        "    }\n",
        "\n",
        "    // Copy host arrays to statically defined device memory\n",
        "    cudaMemcpyToSymbol(d_A, h_A, sizeof(int) * N);\n",
        "    cudaMemcpyToSymbol(d_B, h_B, sizeof(int) * N);\n",
        "\n",
        "    // Timing kernel execution\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    int blockSize = 256;\n",
        "    int numBlocks = (N + blockSize - 1) / blockSize;\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    vectorAdd<<<numBlocks, blockSize>>>();\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    // Copy result back\n",
        "    cudaMemcpyFromSymbol(h_C, d_C, sizeof(int) * N);\n",
        "\n",
        "    // Print sample result\n",
        "    printf(\"Sample output: h_C[100] = %d\\n\", h_C[100]);\n",
        "\n",
        "    // --- Device Properties ---\n",
        "    cudaDeviceProp prop;\n",
        "    cudaGetDeviceProperties(&prop, 0);\n",
        "\n",
        "    float memClock = prop.memoryClockRate; // kHz\n",
        "    int memBusWidth = prop.memoryBusWidth; // bits\n",
        "\n",
        "    float theoreticalBW = 2.0 * memClock * memBusWidth / 8.0 / 1e6; // GB/s\n",
        "    printf(\"Theoretical Bandwidth: %.2f GB/s\\n\", theoreticalBW);\n",
        "\n",
        "    // --- Measured Bandwidth ---\n",
        "    int bytesRead = sizeof(int) * N * 2; // A and B\n",
        "    int bytesWritten = sizeof(int) * N; // C\n",
        "    float seconds = milliseconds / 1000.0;\n",
        "    float measuredBW = (bytesRead + bytesWritten) / seconds / 1e9; // GB/s\n",
        "    printf(\"Measured Bandwidth: %.2f GB/s\\n\", measuredBW);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 vector_add_bandwidth.cu -o vector_add_bandwidth\n",
        "!./vector_add_bandwidth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iG9zLYAVeTG",
        "outputId": "d1516e2d-4773-4aea-9d5c-e277a555329e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample output: h_C[100] = 300\n",
            "Theoretical Bandwidth: 320.06 GB/s\n",
            "Measured Bandwidth: 0.17 GB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./vector_add_bandwidth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2EJQnEwVjFm",
        "outputId": "99766396-8433-416f-ba57-b5b615ddc845"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==462== NVPROF is profiling process 462, command: ./vector_add_bandwidth\n",
            "Sample output: h_C[100] = 300\n",
            "Theoretical Bandwidth: 320.06 GB/s\n",
            "Measured Bandwidth: 0.37 GB/s\n",
            "==462== Profiling application: ./vector_add_bandwidth\n",
            "==462== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   43.15%  3.3280us         1  3.3280us  3.3280us  3.3280us  vectorAdd(void)\n",
            "                   30.29%  2.3360us         1  2.3360us  2.3360us  2.3360us  [CUDA memcpy DtoH]\n",
            "                   26.56%  2.0480us         2  1.0240us  1.0240us  1.0240us  [CUDA memcpy HtoD]\n",
            "      API calls:   99.56%  88.483ms         2  44.242ms  7.7480us  88.475ms  cudaMemcpyToSymbol\n",
            "                    0.18%  161.04us         1  161.04us  161.04us  161.04us  cudaGetDeviceProperties\n",
            "                    0.15%  132.99us       114  1.1660us     107ns  55.893us  cuDeviceGetAttribute\n",
            "                    0.03%  26.320us         1  26.320us  26.320us  26.320us  cudaLaunchKernel\n",
            "                    0.02%  19.960us         1  19.960us  19.960us  19.960us  cudaMemcpyFromSymbol\n",
            "                    0.01%  12.113us         1  12.113us  12.113us  12.113us  cuDeviceGetName\n",
            "                    0.01%  11.451us         2  5.7250us  3.2730us  8.1780us  cudaEventCreate\n",
            "                    0.01%  8.6940us         2  4.3470us  2.9990us  5.6950us  cudaEventRecord\n",
            "                    0.01%  7.3330us         1  7.3330us  7.3330us  7.3330us  cudaEventSynchronize\n",
            "                    0.01%  4.9970us         1  4.9970us  4.9970us  4.9970us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.7210us         3     573ns     136ns     941ns  cuDeviceGetCount\n",
            "                    0.00%  1.6590us         1  1.6590us  1.6590us  1.6590us  cudaEventElapsedTime\n",
            "                    0.00%     825ns         1     825ns     825ns     825ns  cuDeviceTotalMem\n",
            "                    0.00%     699ns         2     349ns     134ns     565ns  cuDeviceGet\n",
            "                    0.00%     294ns         1     294ns     294ns     294ns  cuModuleGetLoadingMode\n",
            "                    0.00%     255ns         1     255ns     255ns     255ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#nvprof- NVIDIA's command line profiler for CUDA programs. Think of it like a detective that watches your gpu code run and tells you stuff like:\n",
        "#Which kernels are being launched\n",
        "##How long they take\n",
        "#How much memory they're using\n",
        "#Whether your GPU is sitting there twiddling its thumbs"
      ],
      "metadata": {
        "id": "wKNBul_vVnuM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}